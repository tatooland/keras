{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KERAS_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatooland/keras/blob/master/KERAS_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvFRDNaSe2C",
        "colab_type": "text"
      },
      "source": [
        "##define GOOGLE DRIVER downloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ZN69_0SSWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def downloadFromGDriver(fileId):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  fileName = fileId + '.zip'\n",
        "  downloaded = drive.CreateFile({'id': fileId})\n",
        "  downloaded.GetContentFile(fileName)\n",
        "  ds = ZipFile(fileName)\n",
        "  ds.extractall()\n",
        "  os.remove(fileName)\n",
        "  print('Extracted zip file ' + fileName)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdbrI5PCTClj",
        "colab_type": "text"
      },
      "source": [
        "## define uncompress zip file processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3wqdi0TF18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "def uncompressZipFile(fileName):\n",
        "   ds = ZipFile(fileName)\n",
        "   ds.extractall()\n",
        "   os.remove(fileName)\n",
        "   print(\"process complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpA2z3mKTIzb",
        "colab_type": "text"
      },
      "source": [
        "##define image iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpmHjv1HTMsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def iteratorImgFolder(folder, callback):\n",
        "  g = os.walk(folder)\n",
        "  ary = []\n",
        "  for path, _, fileList in g:\n",
        "    for fileName in fileList:\n",
        "      callback(os.path.join(path, fileName), ary)\n",
        "  return ary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onX5wf-YTSHt",
        "colab_type": "text"
      },
      "source": [
        "## define image reader\n",
        "\n",
        "\n",
        "###download image data from google driver example:\n",
        "\n",
        "fileId = \"1Uy-VRPQlrjfPHkJlZEgxUH-_4vMI1CUn\"\n",
        "\n",
        "downloadFromGDriver(fileId)\n",
        "\n",
        "uncompressZipFile(\"seg_pred.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_test.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_train.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUX8wq3RTa2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "def readImgAsArray(fileName, ary):\n",
        "  img = load_img(fileName)\n",
        "  format_img = img_to_array(img)\n",
        "  print(format_img.shape)\n",
        "  ary.extend(format_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5PdLkDTmpj",
        "colab_type": "text"
      },
      "source": [
        "##define image pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoFyBCMbTqcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "def readImgDataAsFlow(train_dir, test_dir, validation_dir, target_size=(150, 150)):\n",
        "  trainGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  testGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  validationGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  trainFlow = trainGenerator.flow_from_directory(train_dir, class_mode='categorical', target_size=target_size)\n",
        "  testFlow = testGenerator.flow_from_directory(test_dir, class_mode='categorical', target_size=target_size)\n",
        "  validationFlow = validationGenerator.flow_from_directory(validation_dir, class_mode='categorical', target_size=target_size)\n",
        "  return trainFlow, testFlow, validationFlow\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgFO2eTPWPj8",
        "colab_type": "text"
      },
      "source": [
        "##define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBjQa-Uhth2",
        "colab_type": "text"
      },
      "source": [
        "###DCGAN\n",
        "\n",
        "Notes on Implementation\n",
        "We trained a custom version of the SAGAN model using spectral normalization and self-attention. We used Tensorflowâ€™s tf.keras and Eager execution.\n",
        "\n",
        "The Generator takes a random vector z and generates 128x128 RGB images. All layers, including dense layers, use spectral normalization. Additionally, the generator uses batch normalization and ReLU activations. Also, it uses self-attention in between middle-to-high feature maps. Like in the original implementation, we placed the attention layer to act on feature maps with dimensions 32x32.\n",
        "\n",
        "The discriminator also uses spectral normalization (all layers). It takes RGB image samples of size 128x128 and outputs an unscaled probability. It uses leaky ReLUs with an alpha parameter of 0.02. Like the generator, it also has a self-attention layer operating of feature maps of dimensions 32x32.\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/model_architecture.png)\n",
        "\n",
        "\n",
        "SAGAM model architecture\n",
        "The goal is to minimize the hinge version of the adversarial loss. To do that, we trained the generator and discriminator in an alternating style using the Adam Optimizer.\n",
        "\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/hinge_gan_loss.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[referrence](https://github.com/Goldesel23/DCGAN-for-Bird-Generation/blob/master/traindcgan.py)\n",
        "\n",
        "###tensorflow code below:\n",
        "```\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "```\n",
        "\n",
        "![](https://gluon.mxnet.io/_images/dcgan.png)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization, Dense, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "# Here is where we will load the dataset stored in dataset_path. In this script\n",
        "# we will use the Caltech-UCSD Birds-200-2011 dataset which includes 11788\n",
        "# images from 200 different birds. We will feed the images without applying\n",
        "# the provided bounding boxes from the dataset. The data will only be resized\n",
        "# and normalized. Keras ImageDataGenerator will be used for loading the dataset\n",
        "def load_dataset(dataset_path, batch_size, image_shape):\n",
        "    dataset_generator = ImageDataGenerator()\n",
        "    dataset_generator = dataset_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "\n",
        "    return dataset_generator\n",
        "\n",
        "\n",
        "# Creates the discriminator model. This model tries to classify images as real\n",
        "# or fake.\n",
        "def construct_discriminator(image_shape):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform',\n",
        "                             input_shape=(image_shape)))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(1))\n",
        "    discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=None)\n",
        "\n",
        "    return discriminator\n",
        "\n",
        "\n",
        "# Creates the generator model. This model has an input of random noise and\n",
        "# generates an image that will try mislead the discriminator.\n",
        "def construct_generator():\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(units=4 * 4 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=None)\n",
        "\n",
        "    return generator\n",
        "\n",
        "\n",
        "# Displays a figure of the generated images and saves them in as .png image\n",
        "def save_generated_images(generated_images, epoch, batch_number):\n",
        "\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'generated images/generatedSamples_epoch' + str(\n",
        "        epoch + 1) + '_batch' + str(batch_number + 1) + '.png'\n",
        "\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Main train function\n",
        "def train_dcgan(batch_size, epochs, image_shape, dataset_path):\n",
        "    # Build the adversarial model that consists in the generator output\n",
        "    # connected to the discriminator\n",
        "    generator = construct_generator()\n",
        "    discriminator = construct_discriminator(image_shape)\n",
        "\n",
        "    gan = Sequential()\n",
        "    # Only false for the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                metrics=None)\n",
        "\n",
        "    # Create a dataset Generator with help of keras\n",
        "    dataset_generator = load_dataset(dataset_path, batch_size, image_shape)\n",
        "\n",
        "    # 11788 is the total number of images on the bird dataset\n",
        "    number_of_batches = int(11788 / batch_size)\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allo plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Let's train the DCGAN for n epochs\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \" :\")\n",
        "\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Get the current batch and normalize the images between -1 and 1\n",
        "            real_images = dataset_generator.next()\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size,) + (1, 1, 100))\n",
        "\n",
        "            # Generate images\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                      np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size * 2,) +\n",
        "                                     (1, 1, 100))\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            if((batch_number + 1) % 50 == 0 and\n",
        "               current_batch_size == batch_size):\n",
        "                save_generated_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            # Display and plot the results\n",
        "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                  str(number_of_batches) +\n",
        "                  \" generator loss | discriminator loss : \" +\n",
        "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
        "                  str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Save the model weights each 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            discriminator.trainable = True\n",
        "            generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "            discriminator.save('models/discriminator_epoch' +\n",
        "                               str(epoch) + '.hdf5')\n",
        "\n",
        "        # Each epoch update the loss graphs\n",
        "        plt.figure(1)\n",
        "        plt.plot(batches, adversarial_loss, color='green',\n",
        "                 label='Generator Loss')\n",
        "        plt.plot(batches, discriminator_loss, color='blue',\n",
        "                 label='Discriminator Loss')\n",
        "        plt.title(\"DCGAN Train\")\n",
        "        plt.xlabel(\"Batch Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        if epoch == 0:\n",
        "            plt.legend()\n",
        "        plt.pause(0.0000000001)\n",
        "        plt.show()\n",
        "        plt.savefig('trainingLossPlot.png')\n",
        "\n",
        "\n",
        "def main():\n",
        "    dataset_path = '/home/tfreitas/Datasets/CUB_200_2011/CUB_200_2011/images/'\n",
        "    batch_size = 64\n",
        "    image_shape = (64, 64, 3)\n",
        "    epochs = 190\n",
        "    train_dcgan(batch_size, epochs,\n",
        "                image_shape, dataset_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iv7wEWUWSB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flattenï¼ŒConv2DTranspose, BatchNormalization, LeakyReLU, Reshape\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "#DCGAN\n",
        "\n",
        "\n",
        "\n",
        "def buildGenerator():\n",
        "  modelG = Sequential()\n",
        "  #define fully connection\n",
        "  modelG.add(Dense(4*4*1024, input_dim=100))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU())\n",
        "  \n",
        "  #reshape linear output to cube shape\n",
        "  modelG.add(Reshape((4, 4, 1024)))\n",
        "  \n",
        "  #define transpose convolution\n",
        "  modelG.add(Conv2DTranspose(filters=512, kernel_size=5, strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "  \n",
        "  modelG.add(Conv2DTranspose(filters=256, kernel_size=(5, 5), strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "  \n",
        "  modelG.add(Conv2DTranspose(filters=128, kernel_size=(5, 5), strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "  \n",
        "  modelG.add(Conv2DTranspose(filters=3, kernel_size=(5, 5), strides=2, padding='same', activation='tanh'))\n",
        "  \n",
        "  optimizer = Adam(lr=.00015, beta_l=.5)\n",
        "  modelG.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  return modelG\n",
        "\n",
        "\n",
        "  \n",
        "def buildDiscriminator():\n",
        "  #define discriminator\n",
        "  modelD = Sequentail()\n",
        "  modelD.add(Conv2D(128, kernel_size=(5, 5), padding='same', strides=(2, 2) input_shape=(64, 64, 3)))\n",
        "  modelD.add(LeakyReLU())\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD = Sequentail()\n",
        "  modelD.add(Conv2D(256, kernel_size=(5, 5), padding='same', strides=(2, 2)))\n",
        "  modelD.add(LeakyReLU(alpha=.01))\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD = Sequentail()\n",
        "  modelD.add(Conv2D(512, kernel_size=(5, 5), padding='same', strides=(2, 2)))\n",
        "  modelD.add(LeakyReLU(alpha=.01))\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD.add(Flatten())\n",
        "  modelD.add(Dense(1))\n",
        "  optimizer = Adam(lr=.0002, beta_l=.5)\n",
        "  modelD.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  return modelD\n",
        "\n",
        "def load_dataset(path, batch_size, image_shape):\n",
        "  return\n",
        "\n",
        "def buildDCGAN():\n",
        "  generator = buildGenerator()\n",
        "  discriminator = buildDiscriminator()\n",
        "  \n",
        "  gan = Sequential()\n",
        "  discriminator.trainable = False\n",
        "  gan.add(generator)\n",
        "  gan.add(discriminator)\n",
        "  \n",
        "  optimizer = Adam(lr=.00015, beta_l=.5)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  inputG = load_dataset(path, batch_size, image_shape)\n",
        "  \n",
        "  number_of_batches = int(11788 / batch_size)\n",
        "  \n",
        "  generator_loss = np.empty(shape=1)\n",
        "  discriminator_loss = np.empty(shape=1)\n",
        "  batches = np.empty(shape=1)\n",
        "  \n",
        "  current_batch = 0\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    print(\"Epoch \" + str(epoch + 1) + \"/\" + str(epochs) + \":\")\n",
        "    \n",
        "    for batch_number in range(number_of_batches):\n",
        "      \n",
        "      real_images = inputG.next()\n",
        "      real_images /= 127.5\n",
        "      real_images -= 1\n",
        "      \n",
        "      current_batch_size = real_images.shape[0]\n",
        "      \n",
        "      noise = np.random.normal(0, 1, size=(current_batch_size, 1, 1, 100))\n",
        "      \n",
        "      generator_images = generator.predict(noise)\n",
        "      \n",
        "      real_y = (np.ones(current_batch_size) - np.random.random_sample(current_batch_size) * .2)\n",
        "      fake_y = np.random.random_sample(current_batch_size) * .2\n",
        "      \n",
        "      \n",
        "      #train the discriminator\n",
        "      discriminator.trainable = True\n",
        "      \n",
        "      d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "      d_loss += discriminator.train_on_batch(generator_images, fake_y)\n",
        "      \n",
        "      discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "      \n",
        "      discriminator.trainable = False\n",
        "      \n",
        "      noise = np.random.normal(0, 1, size=(current_batch_size * 2, 1, 1, 100))\n",
        "      \n",
        "      fake_y = (np.ones(current_batch_size * 2) - np.random.random_sample(current_batch_size * 2) * .2)\n",
        "      \n",
        "      g_loss = gan.train_on_batch(noise, fake_y)\n",
        "      generator_loss = np.append(generator_loss, g_loss)\n",
        "      batches = np.append(batches, current_batch)\n",
        "      \n",
        "      if((batch_number + 1) % 50 == 0 and current_batch_size == batch_size):\n",
        "        save_generated_image(generator_images, epoch, batch_number)\n",
        "      \n",
        "      \n",
        "  \n",
        "\n",
        "             \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}