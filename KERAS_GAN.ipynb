{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KERAS_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatooland/keras/blob/master/KERAS_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvFRDNaSe2C",
        "colab_type": "text"
      },
      "source": [
        "##define GOOGLE DRIVER downloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ZN69_0SSWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def downloadFromGDriver(fileId):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  fileName = fileId + '.zip'\n",
        "  downloaded = drive.CreateFile({'id': fileId})\n",
        "  downloaded.GetContentFile(fileName)\n",
        "  ds = ZipFile(fileName)\n",
        "  ds.extractall()\n",
        "  os.remove(fileName)\n",
        "  print('Extracted zip file ' + fileName)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdbrI5PCTClj",
        "colab_type": "text"
      },
      "source": [
        "## define uncompress zip file processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3wqdi0TF18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "def uncompressZipFile(fileName):\n",
        "   ds = ZipFile(fileName)\n",
        "   ds.extractall()\n",
        "   os.remove(fileName)\n",
        "   print(\"process complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpA2z3mKTIzb",
        "colab_type": "text"
      },
      "source": [
        "##define image iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpmHjv1HTMsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def iteratorImgFolder(folder, callback):\n",
        "  g = os.walk(folder)\n",
        "  ary = []\n",
        "  for path, _, fileList in g:\n",
        "    for fileName in fileList:\n",
        "      callback(os.path.join(path, fileName), ary)\n",
        "  return ary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onX5wf-YTSHt",
        "colab_type": "text"
      },
      "source": [
        "## define image reader\n",
        "\n",
        "\n",
        "###download image data from google driver example:\n",
        "\n",
        "fileId = \"1Uy-VRPQlrjfPHkJlZEgxUH-_4vMI1CUn\"\n",
        "\n",
        "downloadFromGDriver(fileId)\n",
        "\n",
        "uncompressZipFile(\"seg_pred.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_test.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_train.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUX8wq3RTa2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "def readImgAsArray(fileName, ary):\n",
        "  img = load_img(fileName)\n",
        "  format_img = img_to_array(img)\n",
        "  print(format_img.shape)\n",
        "  ary.extend(format_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5PdLkDTmpj",
        "colab_type": "text"
      },
      "source": [
        "##define image pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoFyBCMbTqcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "def readImgDataAsFlow(train_dir, test_dir, validation_dir, target_size=(150, 150)):\n",
        "  trainGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  testGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  validationGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  trainFlow = trainGenerator.flow_from_directory(train_dir, class_mode='categorical', target_size=target_size)\n",
        "  testFlow = testGenerator.flow_from_directory(test_dir, class_mode='categorical', target_size=target_size)\n",
        "  validationFlow = validationGenerator.flow_from_directory(validation_dir, class_mode='categorical', target_size=target_size)\n",
        "  return trainFlow, testFlow, validationFlow\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgFO2eTPWPj8",
        "colab_type": "text"
      },
      "source": [
        "##define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBjQa-Uhth2",
        "colab_type": "text"
      },
      "source": [
        "###DCGAN\n",
        "\n",
        "Notes on Implementation\n",
        "We trained a custom version of the SAGAN model using spectral normalization and self-attention. We used Tensorflow’s tf.keras and Eager execution.\n",
        "\n",
        "The Generator takes a random vector z and generates 128x128 RGB images. All layers, including dense layers, use spectral normalization. Additionally, the generator uses batch normalization and ReLU activations. Also, it uses self-attention in between middle-to-high feature maps. Like in the original implementation, we placed the attention layer to act on feature maps with dimensions 32x32.\n",
        "\n",
        "The discriminator also uses spectral normalization (all layers). It takes RGB image samples of size 128x128 and outputs an unscaled probability. It uses leaky ReLUs with an alpha parameter of 0.02. Like the generator, it also has a self-attention layer operating of feature maps of dimensions 32x32.\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/model_architecture.png)\n",
        "\n",
        "\n",
        "SAGAM model architecture\n",
        "The goal is to minimize the hinge version of the adversarial loss. To do that, we trained the generator and discriminator in an alternating style using the Adam Optimizer.\n",
        "\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/hinge_gan_loss.png)\n",
        "\n",
        "###tensorflow code below:\n",
        "```\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "```\n",
        "\n",
        "![](https://gluon.mxnet.io/_images/dcgan.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iv7wEWUWSB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten，Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "#DCGAN\n",
        "def defineDCGANModel():\n",
        "  model = Sequential()\n",
        "  #define fully connection\n",
        "  model.add(Dense(4*4*1024, input_dim=100))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  \n",
        "  #reshape linear output to cube shape\n",
        "  model.add(Reshape((4, 4, 1024)))\n",
        "  \n",
        "  #define transpose convolution\n",
        "  model.add(Conv2DTranspose(filters=512, ))\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}