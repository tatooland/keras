{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KERAS_GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatooland/keras/blob/master/KERAS_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FvFRDNaSe2C",
        "colab_type": "text"
      },
      "source": [
        "##define GOOGLE DRIVER downloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ZN69_0SSWM",
        "colab_type": "code",
        "outputId": "51174570-f710-49e2-c5ed-dd93f6791b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def downloadFromGDriver(fileId):\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  fileName = fileId + '.zip'\n",
        "  downloaded = drive.CreateFile({'id': fileId})\n",
        "  downloaded.GetContentFile(fileName)\n",
        "  ds = ZipFile(fileName)\n",
        "  ds.extractall()\n",
        "  os.remove(fileName)\n",
        "  print('Extracted zip file ' + fileName)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdbrI5PCTClj",
        "colab_type": "text"
      },
      "source": [
        "## define uncompress zip file processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3wqdi0TF18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "def uncompressZipFile(fileName):\n",
        "   ds = ZipFile(fileName)\n",
        "   ds.extractall()\n",
        "   os.remove(fileName)\n",
        "   print(\"process complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpA2z3mKTIzb",
        "colab_type": "text"
      },
      "source": [
        "##define image iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpmHjv1HTMsT",
        "colab_type": "code",
        "outputId": "01e20ca3-760a-42b7-cdbb-bf4141416d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "def iteratorImgFolder(npAry, folder, callback):\n",
        "  g = os.walk(folder)\n",
        "  for path, _, fileList in g:\n",
        "    for fileName in fileList:\n",
        "      callback(os.path.join(path, fileName), npAry)\n",
        "\n",
        "def readImgAsArray(fileName, ary):\n",
        "  img = load_img(fileName)\n",
        "  format_img = img_to_array(img)\n",
        "  print(format_img.shape)\n",
        "  ary.extend(format_img)\n",
        "  \n",
        "def readImgAsNumpyArray(fileName, npAry):\n",
        "  img = cv2.imread(fileName, 1)\n",
        "  img = cv2.resize(img, (64, 64))\n",
        "  print(img.shape)\n",
        "  #cv2_imshow(img)\n",
        "  np.append(npAry, np.asarray(img))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onX5wf-YTSHt",
        "colab_type": "text"
      },
      "source": [
        "## define image reader\n",
        "\n",
        "\n",
        "###download image data from google driver example:\n",
        "\n",
        "fileId = \"1Uy-VRPQlrjfPHkJlZEgxUH-_4vMI1CUn\"\n",
        "\n",
        "downloadFromGDriver(fileId)\n",
        "\n",
        "uncompressZipFile(\"seg_pred.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_test.zip\")\n",
        "\n",
        "uncompressZipFile(\"seg_train.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb5PdLkDTmpj",
        "colab_type": "text"
      },
      "source": [
        "##define image pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoFyBCMbTqcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "def readImgDataAsFlow(train_dir, test_dir, validation_dir, target_size=(150, 150)):\n",
        "  trainGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  testGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  validationGenerator = ImageDataGenerator(data_format=\"channels_last\")\n",
        "  trainFlow = trainGenerator.flow_from_directory(train_dir, class_mode='categorical', target_size=target_size)\n",
        "  testFlow = testGenerator.flow_from_directory(test_dir, class_mode='categorical', target_size=target_size)\n",
        "  validationFlow = validationGenerator.flow_from_directory(validation_dir, class_mode='categorical', target_size=target_size)\n",
        "  return trainFlow, testFlow, validationFlow\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ad_i76ChR77",
        "colab_type": "text"
      },
      "source": [
        "#DOWNLOAD pokemon dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs74F00ahRNe",
        "colab_type": "code",
        "outputId": "c6d55620-cf83-4cf7-cd52-e8bcfc4a8d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "fileId = '11dZYp9zc5wkcl-KU1X_p3trCQ6aDn_x8'\n",
        "downloadFromGDriver(fileId)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0722 03:05:29.377202 140650380330880 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0722 03:05:30.568443 140650380330880 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracted zip file 11dZYp9zc5wkcl-KU1X_p3trCQ6aDn_x8.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oRkkIdPicd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls /content/Pokemon/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WFcBkoXco7W",
        "colab_type": "text"
      },
      "source": [
        "#READ pokemon image as numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDy_9acvjkS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "def loadDataSets():\n",
        "  flist = glob.glob(\"/content/Pokemon/*.jpg\")\n",
        "  images = np.array([np.array(Image.open(fname).resize((64, 64))) for fname in flist])\n",
        "  return images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCRcvNq0gWFh",
        "colab_type": "text"
      },
      "source": [
        "#Model Referrence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBjQa-Uhth2",
        "colab_type": "text"
      },
      "source": [
        "###DCGAN\n",
        "\n",
        "Notes on Implementation\n",
        "We trained a custom version of the SAGAN model using spectral normalization and self-attention. We used Tensorflow’s tf.keras and Eager execution.\n",
        "\n",
        "The Generator takes a random vector z and generates 128x128 RGB images. All layers, including dense layers, use spectral normalization. Additionally, the generator uses batch normalization and ReLU activations. Also, it uses self-attention in between middle-to-high feature maps. Like in the original implementation, we placed the attention layer to act on feature maps with dimensions 32x32.\n",
        "\n",
        "The discriminator also uses spectral normalization (all layers). It takes RGB image samples of size 128x128 and outputs an unscaled probability. It uses leaky ReLUs with an alpha parameter of 0.02. Like the generator, it also has a self-attention layer operating of feature maps of dimensions 32x32.\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/model_architecture.png)\n",
        "\n",
        "\n",
        "SAGAM model architecture\n",
        "The goal is to minimize the hinge version of the adversarial loss. To do that, we trained the generator and discriminator in an alternating style using the Adam Optimizer.\n",
        "\n",
        "\n",
        "![](https://sthalles.github.io/assets/advanced_gans/hinge_gan_loss.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[referrence](https://github.com/Goldesel23/DCGAN-for-Bird-Generation/blob/master/traindcgan.py)\n",
        "\n",
        "###tensorflow code below:\n",
        "```\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "```\n",
        "\n",
        "![](https://gluon.mxnet.io/_images/dcgan.png)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization, Dense, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\n",
        "# Here is where we will load the dataset stored in dataset_path. In this script\n",
        "# we will use the Caltech-UCSD Birds-200-2011 dataset which includes 11788\n",
        "# images from 200 different birds. We will feed the images without applying\n",
        "# the provided bounding boxes from the dataset. The data will only be resized\n",
        "# and normalized. Keras ImageDataGenerator will be used for loading the dataset\n",
        "def load_dataset(dataset_path, batch_size, image_shape):\n",
        "    dataset_generator = ImageDataGenerator()\n",
        "    dataset_generator = dataset_generator.flow_from_directory(\n",
        "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)\n",
        "\n",
        "    return dataset_generator\n",
        "\n",
        "\n",
        "# Creates the discriminator model. This model tries to classify images as real\n",
        "# or fake.\n",
        "def construct_discriminator(image_shape):\n",
        "\n",
        "    discriminator = Sequential()\n",
        "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform',\n",
        "                             input_shape=(image_shape)))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
        "                             strides=(2, 2), padding='same',\n",
        "                             data_format='channels_last',\n",
        "                             kernel_initializer='glorot_uniform'))\n",
        "    discriminator.add(BatchNormalization(momentum=0.5))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "\n",
        "    discriminator.add(Flatten())\n",
        "    discriminator.add(Dense(1))\n",
        "    discriminator.add(Activation('sigmoid'))\n",
        "\n",
        "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=None)\n",
        "\n",
        "    return discriminator\n",
        "\n",
        "\n",
        "# Creates the generator model. This model has an input of random noise and\n",
        "# generates an image that will try mislead the discriminator.\n",
        "def construct_generator():\n",
        "\n",
        "    generator = Sequential()\n",
        "\n",
        "    generator.add(Dense(units=4 * 4 * 512,\n",
        "                        kernel_initializer='glorot_uniform',\n",
        "                        input_shape=(1, 1, 100)))\n",
        "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(BatchNormalization(momentum=0.5))\n",
        "    generator.add(Activation('relu'))\n",
        "\n",
        "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
        "                                  strides=(2, 2), padding='same',\n",
        "                                  data_format='channels_last',\n",
        "                                  kernel_initializer='glorot_uniform'))\n",
        "    generator.add(Activation('tanh'))\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=None)\n",
        "\n",
        "    return generator\n",
        "\n",
        "\n",
        "# Displays a figure of the generated images and saves them in as .png image\n",
        "def save_generated_images(generated_images, epoch, batch_number):\n",
        "\n",
        "    plt.figure(figsize=(8, 8), num=2)\n",
        "    gs1 = gridspec.GridSpec(8, 8)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "\n",
        "    for i in range(64):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        image = generated_images[i, :, :, :]\n",
        "        image += 1\n",
        "        image *= 127.5\n",
        "        fig = plt.imshow(image.astype(np.uint8))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_name = 'generated images/generatedSamples_epoch' + str(\n",
        "        epoch + 1) + '_batch' + str(batch_number + 1) + '.png'\n",
        "\n",
        "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
        "    plt.pause(0.0000000001)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Main train function\n",
        "def train_dcgan(batch_size, epochs, image_shape, dataset_path):\n",
        "    # Build the adversarial model that consists in the generator output\n",
        "    # connected to the discriminator\n",
        "    generator = construct_generator()\n",
        "    discriminator = construct_discriminator(image_shape)\n",
        "\n",
        "    gan = Sequential()\n",
        "    # Only false for the adversarial model\n",
        "    discriminator.trainable = False\n",
        "    gan.add(generator)\n",
        "    gan.add(discriminator)\n",
        "\n",
        "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
        "                metrics=None)\n",
        "\n",
        "    # Create a dataset Generator with help of keras\n",
        "    dataset_generator = load_dataset(dataset_path, batch_size, image_shape)\n",
        "\n",
        "    # 11788 is the total number of images on the bird dataset\n",
        "    number_of_batches = int(11788 / batch_size)\n",
        "\n",
        "    # Variables that will be used to plot the losses from the discriminator and\n",
        "    # the adversarial models\n",
        "    adversarial_loss = np.empty(shape=1)\n",
        "    discriminator_loss = np.empty(shape=1)\n",
        "    batches = np.empty(shape=1)\n",
        "\n",
        "    # Allo plot updates inside for loop\n",
        "    plt.ion()\n",
        "\n",
        "    current_batch = 0\n",
        "\n",
        "    # Let's train the DCGAN for n epochs\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \" :\")\n",
        "\n",
        "        for batch_number in range(number_of_batches):\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Get the current batch and normalize the images between -1 and 1\n",
        "            real_images = dataset_generator.next()\n",
        "            real_images /= 127.5\n",
        "            real_images -= 1\n",
        "\n",
        "            # The last batch is smaller than the other ones, so we need to\n",
        "            # take that into account\n",
        "            current_batch_size = real_images.shape[0]\n",
        "\n",
        "            # Generate noise\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size,) + (1, 1, 100))\n",
        "\n",
        "            # Generate images\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Add some noise to the labels that will be\n",
        "            # fed to the discriminator\n",
        "            real_y = (np.ones(current_batch_size) -\n",
        "                      np.random.random_sample(current_batch_size) * 0.2)\n",
        "            fake_y = np.random.random_sample(current_batch_size) * 0.2\n",
        "\n",
        "            # Let's train the discriminator\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "            d_loss += discriminator.train_on_batch(generated_images, fake_y)\n",
        "\n",
        "            discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "\n",
        "            # Now it's time to train the generator\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            noise = np.random.normal(0, 1,\n",
        "                                     size=(current_batch_size * 2,) +\n",
        "                                     (1, 1, 100))\n",
        "\n",
        "            # We try to mislead the discriminator by giving the opposite labels\n",
        "            fake_y = (np.ones(current_batch_size * 2) -\n",
        "                      np.random.random_sample(current_batch_size * 2) * 0.2)\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, fake_y)\n",
        "            adversarial_loss = np.append(adversarial_loss, g_loss)\n",
        "            batches = np.append(batches, current_batch)\n",
        "\n",
        "            # Each 50 batches show and save images\n",
        "            if((batch_number + 1) % 50 == 0 and\n",
        "               current_batch_size == batch_size):\n",
        "                save_generated_images(generated_images, epoch, batch_number)\n",
        "\n",
        "            time_elapsed = time.time() - start_time\n",
        "\n",
        "            # Display and plot the results\n",
        "            print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
        "                  str(number_of_batches) +\n",
        "                  \" generator loss | discriminator loss : \" +\n",
        "                  str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
        "                  str(time_elapsed) + ' s.')\n",
        "\n",
        "            current_batch += 1\n",
        "\n",
        "        # Save the model weights each 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            discriminator.trainable = True\n",
        "            generator.save('models/generator_epoch' + str(epoch) + '.hdf5')\n",
        "            discriminator.save('models/discriminator_epoch' +\n",
        "                               str(epoch) + '.hdf5')\n",
        "\n",
        "        # Each epoch update the loss graphs\n",
        "        plt.figure(1)\n",
        "        plt.plot(batches, adversarial_loss, color='green',\n",
        "                 label='Generator Loss')\n",
        "        plt.plot(batches, discriminator_loss, color='blue',\n",
        "                 label='Discriminator Loss')\n",
        "        plt.title(\"DCGAN Train\")\n",
        "        plt.xlabel(\"Batch Iteration\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        if epoch == 0:\n",
        "            plt.legend()\n",
        "        plt.pause(0.0000000001)\n",
        "        plt.show()\n",
        "        plt.savefig('trainingLossPlot.png')\n",
        "\n",
        "\n",
        "def main():\n",
        "    dataset_path = '/home/tfreitas/Datasets/CUB_200_2011/CUB_200_2011/images/'\n",
        "    batch_size = 64\n",
        "    image_shape = (64, 64, 3)\n",
        "    epochs = 190\n",
        "    train_dcgan(batch_size, epochs,\n",
        "                image_shape, dataset_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP0u7Pe9n5Cf",
        "colab_type": "text"
      },
      "source": [
        "#define dcgan model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iv7wEWUWSB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten，Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "#DCGAN\n",
        "\n",
        "\n",
        "\n",
        "def buildGenerator():\n",
        "  modelG = Sequential()\n",
        "  #define fully connection\n",
        "  modelG.add(Dense(4*4*1024, input_dim=100))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU())\n",
        "  \n",
        "  #reshape linear output to cube shape\n",
        "  modelG.add(Reshape((4, 4, 1024)))\n",
        "  \n",
        "  #define transpose convolution 8 X 8 X 512\n",
        "  modelG.add(Conv2DTranspose(filters=512, kernel_size=5, strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "   \n",
        "  #16 X 16 X 256\n",
        "  modelG.add(Conv2DTranspose(filters=256, kernel_size=(5, 5), strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "  \n",
        "  #32 X 32 X 128\n",
        "  modelG.add(Conv2DTranspose(filters=128, kernel_size=(5, 5), strides=2, padding='same', data_format='channels_last'))\n",
        "  modelG.add(BatchNormalization())\n",
        "  modelG.add(LeakyReLU(alpha=.01))\n",
        "  \n",
        "  #64 X 64 X 3\n",
        "  modelG.add(Conv2DTranspose(filters=3, kernel_size=(5, 5), strides=2, padding='same', activation='tanh'))\n",
        "  \n",
        "  optimizer = Adam(lr=.00015, beta_l=.5)\n",
        "  modelG.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  return modelG\n",
        "\n",
        "\n",
        "  \n",
        "def buildDiscriminator():\n",
        "  #define discriminator\n",
        "  modelD = Sequential()\n",
        "  modelD.add(Conv2D(128, kernel_size=(5, 5), padding='same', strides=(2, 2) input_shape=(64, 64, 3)))\n",
        "  modelD.add(LeakyReLU())\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD.add(Conv2D(256, kernel_size=(5, 5), padding='same', strides=(2, 2)))\n",
        "  modelD.add(LeakyReLU(alpha=.01))\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD.add(Conv2D(512, kernel_size=(5, 5), padding='same', strides=(2, 2)))\n",
        "  modelD.add(LeakyReLU(alpha=.01))\n",
        "  modelD.add(Dropout(.3))\n",
        "  \n",
        "  modelD.add(Flatten())\n",
        "  modelD.add(Dense(1))\n",
        "  optimizer = Adam(lr=.0002, beta_l=.5)\n",
        "  modelD.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  return modelD\n",
        "\n",
        "def load_dataset(path, batch_size, image_shape):\n",
        "  \n",
        "  return\n",
        "\n",
        "\n",
        "def bothModelsOptimizer():\n",
        "  return Adam(lr=.00015, beta_l=.5)\n",
        "\n",
        "def discriminatorLoss(crossEntropy, realOutput, fakeOutput):\n",
        "  realLoss = crossEntropy(tf.ones_like(realOutput), realOutput)\n",
        "  fakeLoss = crossEntropy(tf.zeros_like(fakeOutput), fakeOutput)\n",
        "  totalLoss = realLoss + fakeLoss\n",
        "  return totalLoss\n",
        "\n",
        "def generatorLoss(crossEntropy, fakeOutput):\n",
        "  return crossEntropy(tf.ones_like(fakeOutput), fakeOutput)\n",
        "\n",
        "\n",
        "def trainStep(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim]) #BATCH_SIZE=100, noise_dim=100\n",
        "  generator = buildGenerator()\n",
        "  discriminator = buildDiscriminator() \n",
        "  \n",
        "  dcgan = Sequential()\n",
        "  dcgan.add(generator)\n",
        "  dcgan.add(discriminator)\n",
        "  dcganOptimizer = bothModelsOptimizer() \n",
        "  dcgan.compile(loss='binary_crossentropy', optimizer=dcganOptimizer, metrics=None)\n",
        "  \n",
        "  \n",
        "  #train discriminator\n",
        "  fakeImages = generator.predict(noise, batch_size=BATCH_SIZE)\n",
        "  realImages = load_dataset().nextBatch()\n",
        "  \n",
        "  DX = np.concatenate((fakeImages, realImage))\n",
        "  DY = [0] * BATCH_SIZE + [1] * BATCH_SIZE\n",
        "  \n",
        "  discriminator.trainable = True\n",
        "  DLoss = discriminator.train_on_batch(DX, DY)\n",
        "  \n",
        "  #train generator \n",
        "  discriminator.trainable = False\n",
        "  noise = tf.random.normal(0, 1, (BATCH_SIZE, noise_dim)) \n",
        "  GLoss = dcgan.train_on_batch(noise, [1] * BATCH_SIZE)\n",
        "  \n",
        "   \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def buildDCGAN(generator, discriminator):\n",
        "  #construct the dcgan model\n",
        "  \n",
        "  dcgan = Sequential()\n",
        "  discriminator.trainable = False\n",
        "  dcgan.add(generator)\n",
        "  dcgan.add(discriminator)\n",
        "  \n",
        "  optimizer = Adam(lr=.00015, beta_l=.5)\n",
        "  dcgan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=None)\n",
        "  \n",
        "  #capture the feeding data\n",
        "  inputG = load_dataset(path, batch_size, image_shape)\n",
        "  \n",
        "  number_of_batches = int(11788 / batch_size)\n",
        "  \n",
        "  generator_loss = np.empty(shape=1)\n",
        "  discriminator_loss = np.empty(shape=1)\n",
        "  batches = np.empty(shape=1)\n",
        "  \n",
        "  current_batch = 0\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    print(\"Epoch \" + str(epoch + 1) + \"/\" + str(epochs) + \":\")\n",
        "    \n",
        "    for batch_number in range(number_of_batches):\n",
        "      \n",
        "      real_images = inputG.next()\n",
        "      real_images /= 127.5\n",
        "      real_images -= 1\n",
        "      \n",
        "      current_batch_size = real_images.shape[0]\n",
        "      \n",
        "      noise = np.random.normal(0, 1, size=(current_batch_size, 1, 1, 100))\n",
        "      \n",
        "      generator_images = generator.predict(noise)\n",
        "      \n",
        "      real_y = (np.ones(current_batch_size) - np.random.random_sample(current_batch_size) * .2)\n",
        "      fake_y = np.random.random_sample(current_batch_size) * .2\n",
        "      \n",
        "      \n",
        "      #train the discriminator\n",
        "      discriminator.trainable = True\n",
        "      \n",
        "      d_loss = discriminator.train_on_batch(real_images, real_y)\n",
        "      d_loss += discriminator.train_on_batch(generator_images, fake_y)\n",
        "      \n",
        "      discriminator_loss = np.append(discriminator_loss, d_loss)\n",
        "      \n",
        "      discriminator.trainable = False\n",
        "      \n",
        "      noise = np.random.normal(0, 1, size=(current_batch_size * 2, 1, 1, 100))\n",
        "      \n",
        "      fake_y = (np.ones(current_batch_size * 2) - np.random.random_sample(current_batch_size * 2) * .2)\n",
        "      \n",
        "      g_loss = ganerator.train_on_batch(noise, fake_y)\n",
        "      generator_loss = np.append(generator_loss, g_loss)\n",
        "      batches = np.append(batches, current_batch)\n",
        "      \n",
        "      if((batch_number + 1) % 50 == 0 and current_batch_size == batch_size):\n",
        "        save_generated_image(generator_images, epoch, batch_number)\n",
        "      \n",
        "      \n",
        "  \n",
        "\n",
        "             \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I92GPGo3Exp8",
        "colab_type": "code",
        "outputId": "f1ed9a54-e325-40e0-da39-502c33ae2b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "import keras\n",
        "print(keras.engine.input_layer.Input())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4697c0bbfdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \"\"\"\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         assert shape is not None, ('Please provide to Input either a `shape`'\n\u001b[0m\u001b[1;32m    168\u001b[0m                                    \u001b[0;34m' or a `batch_shape` argument. Note that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                                    \u001b[0;34m'`shape` does not include the batch '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please provide to Input either a `shape` or a `batch_shape` argument. Note that `shape` does not include the batch dimension."
          ]
        }
      ]
    }
  ]
}